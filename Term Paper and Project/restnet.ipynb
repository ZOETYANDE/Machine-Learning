{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Datasets and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, json, shutil, numpy as np, pandas as pd\n",
    "from glob import glob; from PIL import Image\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "torch.manual_seed(2024)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root, transformations = None):\n",
    "        \n",
    "        self.transformations = transformations\n",
    "        # Read meta data\n",
    "        meta_data = pd.read_csv(\"./Data/train.csv\")\n",
    "        \n",
    "        # Read json file and get class names dictionary\n",
    "        with open(\"./Data/label_num_to_disease_map.json\") as json_file: data = json.load(json_file)\n",
    "        self.cls_names = {int(key): value for key, value in data.items() }\n",
    "        \n",
    "        # Get image file names and their corresponding labels\n",
    "        im_names = list(meta_data[\"image_id\"])\n",
    "        gt_names = list(meta_data[\"label\"])\n",
    "        self.meta_data = {}\n",
    "        \n",
    "        self.cls_counts, count, data_count = {}, 0, 0\n",
    "        for idx, im_path in enumerate(im_names):\n",
    "            fname = f\"./Data/train_images/{im_path}\"\n",
    "            if not os.path.isfile(fname): continue\n",
    "            else: \n",
    "                class_name = self.cls_names[int(gt_names[idx])]\n",
    "                if class_name not in self.cls_counts: self.cls_counts[class_name] = 1; count += 1\n",
    "                else: self.cls_counts[class_name] += 1\n",
    "                self.meta_data[fname] = int(gt_names[idx])\n",
    "        \n",
    "    def __len__(self): return len(self.meta_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        im_path = list(self.meta_data.keys())[idx]\n",
    "        im = Image.open(im_path).convert(\"RGB\")\n",
    "        gt = self.meta_data[im_path]\n",
    "        \n",
    "        if self.transformations is not None: im = self.transformations(im)\n",
    "        \n",
    "        return im, gt\n",
    "    \n",
    "def get_dls(root, transformations, bs, split = [0.9, 0.05, 0.05], ns = 4):\n",
    "    \n",
    "    ds = CustomDataset(root = root, transformations = transformations)\n",
    "    \n",
    "    total_len = len(ds)\n",
    "    tr_len = int(total_len * split[0])\n",
    "    vl_len = int(total_len * split[1])\n",
    "    ts_len = total_len - (tr_len + vl_len)\n",
    "    \n",
    "    # print(\"Total length:\", total_len)\n",
    "    # print(\"Training length:\", tr_len)\n",
    "    # print(\"Validation length:\", vl_len)\n",
    "    # print(\"Test length:\", ts_len)\n",
    "    \n",
    "    tr_ds, vl_ds, ts_ds = random_split(dataset = ds, lengths = [tr_len, vl_len, ts_len])\n",
    "    \n",
    "    # print(len(tr_ds))\n",
    "    # print(len(vl_ds))\n",
    "    # print(len(ts_ds))\n",
    "\n",
    "    \n",
    "    tr_dl, val_dl, ts_dl = DataLoader(tr_ds, batch_size = bs, shuffle = True, num_workers = ns), DataLoader(vl_ds, batch_size = bs, shuffle = False, num_workers = ns), DataLoader(ts_ds, batch_size = 1, shuffle = False, num_workers = ns)\n",
    "    \n",
    "    return tr_dl, val_dl, ts_dl, ds.cls_names\n",
    "\n",
    "root = \"./Data\"\n",
    "mean, std, im_size = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225], 224\n",
    "tfs = T.Compose([T.Resize((im_size, im_size)), T.ToTensor(), T.Normalize(mean = mean, std = std)])\n",
    "tr_dl, val_dl, ts_dl, classes = get_dls(root = root, transformations = tfs, bs = 32)\n",
    "\n",
    "print(len(tr_dl)); print(len(val_dl)); print(len(ts_dl)); print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def tensor_2_im(t, t_type = \"rgb\"):\n",
    "    \n",
    "    gray_tfs = T.Compose([T.Normalize(mean = [ 0.], std = [1/0.5]), T.Normalize(mean = [-0.5], std = [1])])\n",
    "    rgb_tfs = T.Compose([T.Normalize(mean = [ 0., 0., 0. ], std = [ 1/0.229, 1/0.224, 1/0.225 ]), T.Normalize(mean = [ -0.485, -0.456, -0.406 ], std = [ 1., 1., 1. ])])\n",
    "    \n",
    "    invTrans = gray_tfs if t_type == \"gray\" else rgb_tfs \n",
    "    \n",
    "    return (invTrans(t) * 255).detach().squeeze().cpu().permute(1,2,0).numpy().astype(np.uint8) if t_type == \"gray\" else (invTrans(t) * 255).detach().cpu().permute(1,2,0).numpy().astype(np.uint8)\n",
    "\n",
    "def visualize(data, n_ims, rows, cmap = None, cls_names = None):\n",
    "    \n",
    "    assert cmap in [\"rgb\", \"gray\"], \"Rasmni oq-qora yoki rangli ekanini aniqlashtirib bering!\"\n",
    "    if cmap == \"rgb\": cmap = \"viridis\"\n",
    "    \n",
    "    plt.figure(figsize = (20, 10))\n",
    "    indekslar = [random.randint(0, len(data) - 1) for _ in range(n_ims)]\n",
    "    for idx, indeks in enumerate(indekslar):\n",
    "        \n",
    "        im, gt = data[indeks]\n",
    "        # Start plot\n",
    "        plt.subplot(rows, n_ims // rows, idx + 1)\n",
    "        if cmap: plt.imshow(tensor_2_im(im, cmap), cmap=cmap)\n",
    "        else: plt.imshow(tensor_2_im(im))\n",
    "        plt.axis('off')\n",
    "        if cls_names is not None: plt.title(f\"GT -> {cls_names[int(gt)]}\")\n",
    "        else: plt.title(f\"GT -> {gt}\")\n",
    "            \n",
    "visualize(tr_dl.dataset, 20, 4, \"rgb\", list(classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(val_dl.dataset, 20, 4, \"rgb\", list(classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(ts_dl.dataset, 20, 4, \"rgb\", list(classes.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis(root, transformations):\n",
    "    \n",
    "    ds = CustomDataset(root = root, transformations = transformations)\n",
    "    cls_counts, width, text_width = ds.cls_counts,  0.7, 0.05\n",
    "    text_height = 2\n",
    "    cls_names = list(cls_counts.keys()); counts = list(cls_counts.values())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (20, 10))\n",
    "    indices = np.arange(len(counts))\n",
    "\n",
    "    ax.bar(indices, counts, width, color = \"firebrick\")\n",
    "    ax.set_xlabel(\"Class Names\", color = \"red\")\n",
    "    ax.set_xticklabels(cls_names, rotation = 60)\n",
    "    ax.set(xticks = indices, xticklabels = cls_names)\n",
    "    ax.set_ylabel(\"Data Counts\", color = \"red\")\n",
    "    ax.set_title(f\"Dataset Class Imbalance Analysis\")\n",
    "\n",
    "    for i, v in enumerate(counts): ax.text(i - text_width, v + text_height, str(v), color = \"royalblue\")\n",
    "    \n",
    "data_analysis(root = root, transformations = tfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Model Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA for acceleration.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Create the model\n",
    "m = timm.create_model(\"rexnet_150\", pretrained=True, num_classes=len(classes)).to(device)\n",
    "\n",
    "# Define training setup\n",
    "def train_setup(m):\n",
    "    return m.eval(), 10, torch.nn.CrossEntropyLoss(), torch.optim.Adam(params=m.parameters(), lr=3e-4)\n",
    "\n",
    "def to_device(batch, device):\n",
    "    return batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "def get_metrics(model, ims, gts, loss_fn, epoch_loss, epoch_acc, epoch_f1):\n",
    "    preds = model(ims)\n",
    "    loss = loss_fn(preds, gts)\n",
    "    return loss, epoch_loss + loss.item(), epoch_acc + (torch.argmax(preds, dim=1) == gts).sum().item(), epoch_f1 + f1_score(preds, gts)\n",
    "\n",
    "# Setup training\n",
    "m, epochs, loss_fn, optimizer = train_setup(m)\n",
    "\n",
    "# Setup evaluation metric\n",
    "f1_score = torchmetrics.F1Score(task=\"multiclass\", num_classes=len(classes)).to(device)\n",
    "\n",
    "save_prefix, save_dir = \"crop\", \"saved_models\"\n",
    "print(\"Start training...\")\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "threshold = 0.01\n",
    "not_improved = 0\n",
    "patience = 5\n",
    "\n",
    "tr_losses, val_losses, tr_accs, val_accs, tr_f1s, val_f1s = [], [], [], [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc, epoch_f1 = 0, 0, 0\n",
    "    \n",
    "    # Training\n",
    "    for idx, batch in tqdm(enumerate(tr_dl)):\n",
    "        ims, gts = to_device(batch, device)\n",
    "        loss, epoch_loss, epoch_acc, epoch_f1 = get_metrics(m, ims, gts, loss_fn, epoch_loss, epoch_acc, epoch_f1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tr_loss_to_track = epoch_loss / len(tr_dl)\n",
    "    tr_acc_to_track = epoch_acc / len(tr_dl.dataset)\n",
    "    tr_f1_to_track = epoch_f1 / len(tr_dl)\n",
    "    tr_losses.append(tr_loss_to_track)\n",
    "    tr_accs.append(tr_acc_to_track)\n",
    "    tr_f1s.append(tr_f1_to_track)\n",
    "\n",
    "    print(f\"{epoch + 1}-epoch train process is completed!\")\n",
    "    print(f\"{epoch + 1}-epoch train loss          -> {tr_loss_to_track:.3f}\")\n",
    "    print(f\"{epoch + 1}-epoch train accuracy      -> {tr_acc_to_track:.3f}\")\n",
    "    print(f\"{epoch + 1}-epoch train f1-score      -> {tr_f1_to_track:.3f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        val_epoch_loss, val_epoch_acc, val_epoch_f1 = 0, 0, 0\n",
    "        for idx, batch in enumerate(val_dl):\n",
    "            ims, gts = to_device(batch, device)\n",
    "            loss, val_epoch_loss, val_epoch_acc, val_epoch_f1 = get_metrics(m, ims, gts, loss_fn, val_epoch_loss, val_epoch_acc, val_epoch_f1)\n",
    "\n",
    "        val_loss_to_track = val_epoch_loss / len(val_dl)\n",
    "        val_acc_to_track = val_epoch_acc / len(val_dl.dataset)\n",
    "        val_f1_to_track = val_epoch_f1 / len(val_dl)\n",
    "        val_losses.append(val_loss_to_track)\n",
    "        val_accs.append(val_acc_to_track)\n",
    "        val_f1s.append(val_f1_to_track)\n",
    "\n",
    "        print(f\"{epoch + 1}-epoch validation process is completed!\")\n",
    "        print(f\"{epoch + 1}-epoch validation loss     -> {val_loss_to_track:.3f}\")\n",
    "        print(f\"{epoch + 1}-epoch validation accuracy -> {val_acc_to_track:.3f}\")\n",
    "        print(f\"{epoch + 1}-epoch validation f1-score -> {val_f1_to_track:.3f}\")\n",
    "\n",
    "    # Check for improvement in validation loss\n",
    "    if val_loss_to_track < (best_loss + threshold):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        best_loss = val_loss_to_track\n",
    "        torch.save(m.state_dict(), f\"{save_dir}/{save_prefix}_best_model.pth\")\n",
    "    else:\n",
    "        not_improved += 1\n",
    "        print(f\"Loss value did not decrease for {not_improved} epochs\")\n",
    "        if not_improved == patience:\n",
    "            print(f\"Stop training since loss value did not decrease for {patience} epochs.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLearningCurves:\n",
    "    \n",
    "    def __init__(self, tr_losses, val_losses, tr_accs, val_accs, tr_f1s, val_f1s):\n",
    "        \n",
    "        self.tr_losses, self.val_losses, self.tr_accs, self.val_accs, self.tr_f1s, self.val_f1s = tr_losses, val_losses, tr_accs, val_accs, tr_f1s, val_f1s\n",
    "        \n",
    "    def plot(self, array_1, array_2, label_1, label_2, color_1, color_2):\n",
    "        \n",
    "        plt.plot(array_1, label = label_1, c = color_1); plt.plot(array_2, label = label_2, c = color_2)\n",
    "        \n",
    "    def create_figure(self): plt.figure(figsize = (10, 5))\n",
    "    \n",
    "    def decorate(self, ylabel, xlabel = \"Epochs\"): \n",
    "        \n",
    "        plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
    "        plt.xticks(ticks = np.arange(len(self.tr_accs)), labels = [i for i in range(1, len(self.tr_accs) + 1)])\n",
    "        plt.legend(); plt.show()      \n",
    "        \n",
    "    def visualize(self):\n",
    "        \n",
    "        # Figure 1\n",
    "        self.create_figure()\n",
    "        self.plot(array_1 = self.tr_losses, array_2 = self.val_losses, label_1 = \"Train Loss\", label_2 = \"Validation Loss\", color_1 = \"red\", color_2 = \"blue\"); self.decorate(ylabel = \"Loss Values\")\n",
    "        \n",
    "        # Figure 2\n",
    "        self.create_figure()\n",
    "        self.plot(array_1 = self.tr_accs, array_2 = self.val_accs, label_1 = \"Train Accuracy\", label_2 = \"Validation Accuracy\", color_1 = \"orangered\", color_2 = \"darkgreen\")\n",
    "        self.decorate(ylabel = \"Accuracy Scores\")\n",
    "        \n",
    "        # Figure 3\n",
    "        self.create_figure()\n",
    "        self.plot(array_1 = [tr_f1.cpu() for tr_f1 in self.tr_f1s], array_2 = [vl_f1.cpu() for vl_f1 in self.val_f1s], label_1 = \"Train F1 Score\", label_2 = \"Validation F1 Score\", color_1 = \"blueviolet\", color_2 = \"crimson\"); self.decorate(ylabel = \"F1 Scores\")\n",
    "        \n",
    "PlotLearningCurves(tr_losses, val_losses, tr_accs, val_accs, tr_f1s, val_f1s).visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference and MNodel Training with GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "class SaveFeatures():\n",
    "    \n",
    "    \"\"\" Extract pretrained activations\"\"\"\n",
    "    features = None\n",
    "    def __init__(self, m):\n",
    "        self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.features = ((output.cpu()).data).numpy()\n",
    "    def remove(self): self.hook.remove()\n",
    "\n",
    "def getCAM(conv_fs, linear_weights, class_idx):\n",
    "    \n",
    "    bs, chs, h, w = conv_fs.shape\n",
    "    cam = linear_weights[class_idx].dot(conv_fs[0,:, :, ].reshape((chs, h * w)))\n",
    "    cam = cam.reshape(h, w)\n",
    "    \n",
    "    return (cam - np.min(cam)) / np.max(cam)\n",
    "\n",
    "def inference(model, device, test_dl, num_ims, row, final_conv, fc_params, cls_names = None):\n",
    "    \n",
    "    weight, acc = np.squeeze(fc_params[0].cpu().data.numpy()), 0\n",
    "    activated_features = SaveFeatures(final_conv)\n",
    "    preds, images, lbls = [], [], []\n",
    "    for idx, batch in tqdm(enumerate(test_dl)):\n",
    "        im, gt = to_device(batch, device)\n",
    "        pred_class = torch.argmax(model(im), dim = 1)\n",
    "        acc += (pred_class == gt).sum().item()\n",
    "        images.append(im)\n",
    "        preds.append(pred_class.item())\n",
    "        lbls.append(gt.item())\n",
    "    \n",
    "    print(f\"Accuracy of the model on the test data -> {(acc / len(test_dl.dataset)):.3f}\")\n",
    "    \n",
    "    plt.figure(figsize = (20, 10))\n",
    "    indekslar = [random.randint(0, len(images) - 1) for _ in range(num_ims)]\n",
    "    \n",
    "    for idx, indeks in enumerate(indekslar):\n",
    "        \n",
    "        im = images[indeks].squeeze()\n",
    "        pred_idx = preds[indeks]\n",
    "        heatmap = getCAM(activated_features.features, weight, pred_idx)\n",
    "        \n",
    "        # Start plot\n",
    "        plt.subplot(row, num_ims // row, idx + 1)\n",
    "        plt.imshow(tensor_2_im(im), cmap = \"gray\"); plt.axis(\"off\")\n",
    "        plt.imshow(cv2.resize(heatmap, (im_size, im_size), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet'); plt.axis(\"off\")\n",
    "        \n",
    "        if cls_names is not None: plt.title(f\"GT -> {cls_names[int(lbls[indeks])]} ; PRED -> {cls_names[int(preds[indeks])]}\", color=(\"green\" if {cls_names[int(lbls[indeks])]} == {cls_names[int(preds[indeks])]} else \"red\"))\n",
    "        else: plt.title(f\"GT -> {gt} ; PRED -> {pred}\")\n",
    "\n",
    "m.load_state_dict(torch.load(f\"{save_dir}/{save_prefix}_best_model.pth\"))\n",
    "m.eval()\n",
    "final_conv, fc_params = m.features[-1], list(m.head.fc.parameters())\n",
    "inference(model = m.to(device), device = device, test_dl = ts_dl, num_ims = 20, row = 4, cls_names = list(classes.values()), final_conv = final_conv, fc_params = fc_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
