{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-28T05:35:19.625042Z","iopub.status.busy":"2024-03-28T05:35:19.623917Z","iopub.status.idle":"2024-03-28T05:35:20.610649Z","shell.execute_reply":"2024-03-28T05:35:20.609578Z","shell.execute_reply.started":"2024-03-28T05:35:19.625002Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["./dataset/sample_submission.csv\n","./dataset/test.csv\n","./dataset/train.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('./dataset/'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:20.612677Z","iopub.status.busy":"2024-03-28T05:35:20.612299Z","iopub.status.idle":"2024-03-28T05:35:27.255062Z","shell.execute_reply":"2024-03-28T05:35:27.254019Z","shell.execute_reply.started":"2024-03-28T05:35:20.612652Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import torch.nn.functional as F\n","import pandas as pd\n","import numpy as np\n","import torch.optim as optim\n","import os\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:27.257648Z","iopub.status.busy":"2024-03-28T05:35:27.256606Z","iopub.status.idle":"2024-03-28T05:35:27.263427Z","shell.execute_reply":"2024-03-28T05:35:27.261914Z","shell.execute_reply.started":"2024-03-28T05:35:27.257613Z"},"trusted":true},"outputs":[],"source":["## Checking availability of GPU\n","\n","if torch.cuda.is_available():\n","    device = torch.device(type='cuda',index=0)\n","else:\n","    device = torch.device(type='cpu',index=0)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:27.265985Z","iopub.status.busy":"2024-03-28T05:35:27.265324Z","iopub.status.idle":"2024-03-28T05:35:27.283811Z","shell.execute_reply":"2024-03-28T05:35:27.282595Z","shell.execute_reply.started":"2024-03-28T05:35:27.265946Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cpu', index=0)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"markdown","metadata":{},"source":["# **Custom classes for reading train/test data**"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:27.288965Z","iopub.status.busy":"2024-03-28T05:35:27.288173Z","iopub.status.idle":"2024-03-28T05:35:27.299808Z","shell.execute_reply":"2024-03-28T05:35:27.298892Z","shell.execute_reply.started":"2024-03-28T05:35:27.288909Z"},"trusted":true},"outputs":[],"source":["# Train -- Custom dataset\n","class CustomTrainDataset(Dataset):\n","    \n","    def __init__(self,path,transform):\n","        super().__init__()\n","        self.data = pd.read_csv(path,header='infer').values\n","        self.length = self.data.shape[0]\n","        self.transform = transform # image converted to pytorch tensor\n","        \n","    def __len__(self):\n","        return self.length\n","    \n","    def __getitem__(self,idx):\n","        img = self.data[idx,1:].astype(np.uint8)\n","        img = self.transform(np.reshape(img,(28,28,1))) # 1d to readable image\n","        label = self.data[idx,0]\n","        return img,label\n","    \n","# Test -- Custom dataset\n","class CustomTestDataset(Dataset):\n","    \n","    def __init__(self,path,transform):\n","        super().__init__()\n","        self.data = pd.read_csv(path,header='infer').values\n","        self.length = self.data.shape[0]\n","        self.transform = transform # image converted to pytorch tensor\n","        \n","    def __len__(self):\n","        return self.length\n","    \n","    def __getitem__(self,idx):\n","        img = self.data[idx,:].astype(np.uint8)\n","        img = self.transform(np.reshape(img,(28,28,1))) # 1d to readable image\n","        return img"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:27.302110Z","iopub.status.busy":"2024-03-28T05:35:27.301104Z","iopub.status.idle":"2024-03-28T05:35:33.153357Z","shell.execute_reply":"2024-03-28T05:35:33.152323Z","shell.execute_reply.started":"2024-03-28T05:35:27.302071Z"},"trusted":true},"outputs":[],"source":["train_data = CustomTrainDataset('./dataset/train.csv',ToTensor())\n","test_data = CustomTestDataset('./dataset/test.csv',ToTensor())"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:33.154682Z","iopub.status.busy":"2024-03-28T05:35:33.154405Z","iopub.status.idle":"2024-03-28T05:35:33.160298Z","shell.execute_reply":"2024-03-28T05:35:33.159160Z","shell.execute_reply.started":"2024-03-28T05:35:33.154658Z"},"trusted":true},"outputs":[],"source":["batch_size = 64\n","\n","train_dataloader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True)\n","test_dataloader = DataLoader(dataset=test_data,batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["# CNN Model****"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:33.162996Z","iopub.status.busy":"2024-03-28T05:35:33.162196Z","iopub.status.idle":"2024-03-28T05:35:33.183935Z","shell.execute_reply":"2024-03-28T05:35:33.182559Z","shell.execute_reply.started":"2024-03-28T05:35:33.162954Z"},"trusted":true},"outputs":[],"source":["class mnist_CNN(nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        \n","        self.relu = nn.ReLU()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=1,\n","                               out_channels = 32,\n","                              kernel_size=(3,3),\n","                              stride=1,\n","                              padding=0)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        \n","        self.mp = nn.MaxPool2d(kernel_size=(2,2),\n","                              stride=2,\n","                              padding=0)\n","        self.conv2 = nn.Conv2d(in_channels=32,\n","                              out_channels=64,\n","                              kernel_size=(3,3),\n","                              stride=1,\n","                              padding=0)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        \n","        self.conv3 = nn.Conv2d(in_channels=64,\n","                              out_channels=128,\n","                              kernel_size=(3,3),\n","                              stride=1,\n","                              padding=0)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=128,\n","                              out_channels=200,\n","                              kernel_size=(3,3),\n","                              stride=1,\n","                              padding=0)\n","        self.bn4 = nn.BatchNorm2d(200)\n","        \n","        self.drop = nn.Dropout(0.3)\n","        \n","        self.lin1 = nn.Linear(in_features=64*200,out_features=10)\n","        self.bn5 = nn.BatchNorm1d(10)\n","        \n","        self.flatten = nn.Flatten()\n","        \n","    def forward(self,x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        \n","        x = self.drop(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        \n","        x = self.drop(x)\n","        x = self.mp(x)\n","         \n","        x = self.conv3(x)\n","        x = self.bn3(x)\n","        x = self.relu(x)\n","        \n","        x = self.conv4(x)\n","        x = self.bn4(x)\n","        x = self.relu(x)\n","        \n","        x = self.drop(x)\n","        \n","        x = self.flatten(x)\n","        x = self.lin1(x)\n","        output = self.bn5(x)\n","        \n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["**Training and Testing of model**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:33.185664Z","iopub.status.busy":"2024-03-28T05:35:33.185331Z","iopub.status.idle":"2024-03-28T05:35:33.199971Z","shell.execute_reply":"2024-03-28T05:35:33.199009Z","shell.execute_reply.started":"2024-03-28T05:35:33.185637Z"},"trusted":true},"outputs":[],"source":["def train_epoch(model, train_dataloader, loss_fn, optimizer, device):\n","    model.train()\n","    track_loss = 0\n","    correct = 0\n","    \n","    for i, (img,label) in enumerate(train_dataloader):\n","        \n","        img, label = img.to(device), label.to(device)\n","        \n","        y_pred_train = model(img)\n","        loss_train = loss_fn(y_pred_train, label)\n","        \n","        track_loss += loss_train.item()\n","        correct += (torch.argmax(y_pred_train, dim=1)==label).type(torch.float).sum().item()\n","        \n","        loss_train.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    epoch_loss = track_loss/len(train_dataloader)\n","    epoch_acc = (correct/len(train_dataloader.dataset)) * 100\n","    \n","    return epoch_loss, epoch_acc"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T05:35:33.202317Z","iopub.status.busy":"2024-03-28T05:35:33.201401Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch no: 1\n","training: epoch loss 0.3551420935031304 Epoch Accuracy 96.81428571428572\n","----------------------------------------\n","Epoch no: 2\n","training: epoch loss 0.15239427379889575 Epoch Accuracy 98.60714285714286\n","----------------------------------------\n","Epoch no: 3\n","training: epoch loss 0.09830335356986868 Epoch Accuracy 98.85238095238094\n","----------------------------------------\n","Epoch no: 4\n","training: epoch loss 0.071147830122047 Epoch Accuracy 99.04523809523809\n","----------------------------------------\n","Epoch no: 5\n","training: epoch loss 0.05529971039872418 Epoch Accuracy 99.17857142857143\n","----------------------------------------\n","Epoch no: 6\n","training: epoch loss 0.04676989178758687 Epoch Accuracy 99.16428571428571\n","----------------------------------------\n","Epoch no: 7\n","training: epoch loss 0.03898860560375715 Epoch Accuracy 99.30238095238096\n","----------------------------------------\n","Epoch no: 8\n","training: epoch loss 0.032507344804664495 Epoch Accuracy 99.37619047619047\n","----------------------------------------\n","Epoch no: 9\n","training: epoch loss 0.02920268825149019 Epoch Accuracy 99.43809523809523\n","----------------------------------------\n","Epoch no: 10\n","training: epoch loss 0.02588433099278395 Epoch Accuracy 99.46666666666667\n","----------------------------------------\n","Epoch no: 11\n","training: epoch loss 0.024372721286178702 Epoch Accuracy 99.50238095238095\n","----------------------------------------\n","Epoch no: 12\n","training: epoch loss 0.019396085159206704 Epoch Accuracy 99.61190476190475\n","----------------------------------------\n","Epoch no: 13\n","training: epoch loss 0.01741988007142244 Epoch Accuracy 99.69047619047619\n","----------------------------------------\n","Epoch no: 14\n","training: epoch loss 0.02031295333600559 Epoch Accuracy 99.56666666666666\n","----------------------------------------\n","Epoch no: 15\n","training: epoch loss 0.01672161868886804 Epoch Accuracy 99.61428571428571\n","----------------------------------------\n","Epoch no: 16\n","training: epoch loss 0.015757972999869974 Epoch Accuracy 99.6547619047619\n","----------------------------------------\n","Epoch no: 17\n","training: epoch loss 0.013092042448224508 Epoch Accuracy 99.73095238095237\n","----------------------------------------\n","Epoch no: 18\n","training: epoch loss 0.012892145884104209 Epoch Accuracy 99.72142857142858\n","----------------------------------------\n"]}],"source":["model = mnist_CNN()\n","model = model.to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","learning_rate = 0.001\n","\n","optm = optim.Adam(model.parameters(),lr = learning_rate, weight_decay=1e-5)\n","\n","scheduler = optim.lr_scheduler.StepLR(optm, step_size=5, gamma=0.1)\n","\n","epochs = 18\n","\n","for epoch in range(epochs):\n","    print(\"Epoch no:\",epoch+1)\n","    \n","    train_loss, train_acc = train_epoch(model,\n","                                       train_dataloader,\n","                                       loss_fn,\n","                                       optm,\n","                                       device)\n","    \n","    print(\"training: epoch loss\",train_loss, \"Epoch Accuracy\",train_acc)\n","    \n","    print(\"--\"*20)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 99.88571428571429%\n"]}],"source":["correct = 0\n","total = 0\n","\n","with torch.inference_mode():\n","    model.eval()\n","    for i, (img,label) in enumerate(train_dataloader):\n","        \n","        img = img.to(device)\n","        label = label.to(device)\n","        \n","        pred = model(img)\n","        \n","        predicted = torch.argmax(pred,dim=1).type(torch.int).to(device)\n","        total += label.size(0)\n","        correct += (predicted == label).sum().item()\n","        \n","train_accuracy = 100 * correct / total\n","print(f\"Accuracy: {train_accuracy}%\")"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def evaluate_final(data, model, loss_fn, output_csv):\n","    model.eval()\n","    df = pd.read_csv(output_csv)\n","    \n","    with torch.inference_mode():\n","        for i,img in enumerate(data):\n","            img = img.to(device)\n","            prediction = model(img)\n","            \n","            prediction = torch.argmax(prediction,dim=1).type(torch.int).cpu()\n","            \n","            df.iloc[i*batch_size:i*batch_size + batch_size,1] = prediction.numpy()\n","    df.to_csv('submission.csv',index=False)\n","    df.head()\n","    \n","# it's time\n","evaluate_final(test_dataloader,\n","              model,\n","              loss_fn,\n","              './dataset/sample_submission.csv')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":861823,"sourceId":3004,"sourceType":"competition"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
